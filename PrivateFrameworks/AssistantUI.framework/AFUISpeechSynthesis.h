/*
* This header is generated by classdump-dyld 1.0
* on Thursday, September 24, 2020 at 12:39:57 AM British Summer Time
* Operating System: Version 14.0 (Build 18A373)
* Image Source: /System/Library/PrivateFrameworks/AssistantUI.framework/AssistantUI
* classdump-dyld is licensed under GPLv3, Copyright Â© 2013-2016 by Elias Limneos.
*/

#import <AssistantUI/AssistantUI-Structs.h>
#import <libobjc.A.dylib/AFQueueDelegate.h>
#import <libobjc.A.dylib/AFUIPowerLevelListenerDelegate.h>
#import <libobjc.A.dylib/AFUISpeechSynthesisElementDelegate.h>
#import <libobjc.A.dylib/VSSpeechSynthesizerDelegate.h>
#import <libobjc.A.dylib/AFUISpeechSynthesis.h>

@protocol AFUISpeechSynthesis <NSObject>
@required
-(void)cancel;
-(void)invalidate;
-(void)enqueueText:(id)arg1 identifier:(id)arg2 language:(id)arg3 gender:(id)arg4 isPhonetic:(BOOL)arg5 provisionally:(BOOL)arg6 eligibleAfterDuration:(double)arg7 delayed:(BOOL)arg8 canUseServerTTS:(BOOL)arg9 preparationIdentifier:(id)arg10 completion:(/*^block*/id)arg11 animationIdentifier:(id)arg12 analyticsContext:(id)arg13 speakableContextInfo:(id)arg14;
-(void)enqueueText:(id)arg1 identifier:(id)arg2 completion:(/*^block*/id)arg3;
-(void)enqueueAudioData:(id)arg1 identifier:(id)arg2 provisionally:(BOOL)arg3 eligibleAfterDuration:(double)arg4 completion:(/*^block*/id)arg5;
-(void)enqueuePhaticWithCompletion:(/*^block*/id)arg1;
-(void)processDelayedItem:(id)arg1;
-(void)skipCurrentSynthesis;
-(void)prewarmIfNeeded;

@end


@protocol OS_dispatch_queue, OS_dispatch_group, AFUISpeechSynthesisDelegate, AFUISpeechSynthesisLocalDelegate;
@class VSSpeechSynthesizer, AFSiriClientStateManager, AFVoiceInfo, NSMutableDictionary, NSObject, AFUIPowerLevelListener, AFQueue, NSMutableArray, NSString;

@interface AFUISpeechSynthesis : NSObject <AFQueueDelegate, AFUIPowerLevelListenerDelegate, AFUISpeechSynthesisElementDelegate, VSSpeechSynthesizerDelegate, AFUISpeechSynthesis> {

	VSSpeechSynthesizer* _synthesizer;
	AFSiriClientStateManager* _siriClientStateManager;
	unsigned _sessionID;
	AFVoiceInfo* _outputVoice;
	NSMutableDictionary* _availableVoicesForLanguage;
	NSObject*<OS_dispatch_queue> _processingElementsQueue;
	NSObject*<OS_dispatch_queue> _pendingElementsQueue;
	NSObject*<OS_dispatch_group> _pendingElementsGroup;
	id<AFUISpeechSynthesisDelegate> _delegate;
	id<AFUISpeechSynthesisLocalDelegate> _localDelegate;
	AFUIPowerLevelListener* _powerLevelListener;
	AFQueue* _elementQueue;
	NSMutableArray* _activeElements;
	NSMutableDictionary* _delayedElements;

}

@property (getter=_elementQueue,nonatomic,readonly) AFQueue * elementQueue;                                //@synthesize elementQueue=_elementQueue - In the implementation block
@property (getter=_activeElements,nonatomic,readonly) NSMutableArray * activeElements;                     //@synthesize activeElements=_activeElements - In the implementation block
@property (getter=_delayedElements,nonatomic,readonly) NSMutableDictionary * delayedElements;              //@synthesize delayedElements=_delayedElements - In the implementation block
@property (assign,nonatomic,__weak) id<AFUISpeechSynthesisLocalDelegate> localDelegate;                    //@synthesize localDelegate=_localDelegate - In the implementation block
@property (nonatomic,retain) id<AFUISpeechSynthesisDelegate> delegate;                                     //@synthesize delegate=_delegate - In the implementation block
@property (readonly) unsigned long long hash; 
@property (readonly) Class superclass; 
@property (copy,readonly) NSString * description; 
@property (copy,readonly) NSString * debugDescription; 
-(void)cancel;
-(void)invalidate;
-(void)setOutputVoice:(id)arg1 ;
-(void)queue:(id)arg1 didEnqueueObjects:(id)arg2 ;
-(id)init;
-(BOOL)isSpeaking;
-(void)setDelegate:(id<AFUISpeechSynthesisDelegate>)arg1 ;
-(void)setAudioSessionID:(unsigned)arg1 ;
-(id<AFUISpeechSynthesisDelegate>)delegate;
-(id)_synthesizer;
-(void)speechSynthesizer:(id)arg1 didStartSpeakingRequest:(id)arg2 ;
-(void)speechSynthesizer:(id)arg1 didFinishSpeakingRequest:(id)arg2 successfully:(BOOL)arg3 phonemesSpoken:(id)arg4 withError:(id)arg5 ;
-(void)speechSynthesizer:(id)arg1 didFinishSpeakingRequest:(id)arg2 withInstrumentMetrics:(id)arg3 ;
-(void)speechSynthesizer:(id)arg1 didStartPresynthesizedAudioRequest:(id)arg2 ;
-(void)speechSynthesizer:(id)arg1 didStopPresynthesizedAudioRequest:(id)arg2 atEnd:(BOOL)arg3 error:(id)arg4 ;
-(void)speechSynthesizer:(id)arg1 didFinishPresynthesizedAudioRequest:(id)arg2 withInstrumentMetrics:(id)arg3 error:(id)arg4 ;
-(void)enqueueText:(id)arg1 identifier:(id)arg2 language:(id)arg3 gender:(id)arg4 isPhonetic:(BOOL)arg5 provisionally:(BOOL)arg6 eligibleAfterDuration:(double)arg7 delayed:(BOOL)arg8 canUseServerTTS:(BOOL)arg9 preparationIdentifier:(id)arg10 completion:(/*^block*/id)arg11 animationIdentifier:(id)arg12 analyticsContext:(id)arg13 speakableContextInfo:(id)arg14 ;
-(void)enqueueText:(id)arg1 identifier:(id)arg2 completion:(/*^block*/id)arg3 ;
-(void)enqueueAudioData:(id)arg1 identifier:(id)arg2 provisionally:(BOOL)arg3 eligibleAfterDuration:(double)arg4 completion:(/*^block*/id)arg5 ;
-(void)enqueuePhaticWithCompletion:(/*^block*/id)arg1 ;
-(void)processDelayedItem:(id)arg1 ;
-(void)skipCurrentSynthesis;
-(void)prewarmIfNeeded;
-(void)setLocalDelegate:(id<AFUISpeechSynthesisLocalDelegate>)arg1 ;
-(id<AFUISpeechSynthesisLocalDelegate>)localDelegate;
-(void)speechSynthesisElementSynthesisEligibilityDidChange:(id)arg1 ;
-(BOOL)_isSynthesisQueueEmpty;
-(id)_activeElements;
-(id)_elementQueue;
-(void)_cancelByCancellingActiveElementsOnly:(BOOL)arg1 ;
-(void)invalidateOnMainThread;
-(id)_siriClientStateManager;
-(void)_processElementQueue;
-(id)_activeElementWithPresynthesizedAudioRequest:(id)arg1 ;
-(id)_activeElementWithSpeechRequest:(id)arg1 ;
-(void)_enqueueText:(id)arg1 audioData:(id)arg2 identifier:(id)arg3 language:(id)arg4 gender:(id)arg5 isPhonetic:(BOOL)arg6 provisionally:(BOOL)arg7 eligibleAfterDuration:(double)arg8 delayed:(BOOL)arg9 canUseServerTTS:(BOOL)arg10 preparationIdentifier:(id)arg11 shouldCache:(BOOL)arg12 synthesizesWhileRecording:(BOOL)arg13 completion:(/*^block*/id)arg14 animationIdentifier:(id)arg15 analyticsContext:(id)arg16 speakableContextInfo:(id)arg17 ;
-(id)_delayedElements;
-(void)_findVoiceForLanguage:(id)arg1 gender:(id)arg2 completion:(/*^block*/id)arg3 ;
-(void)_processProvisionalElements;
-(void)_handleAudioData:(id)arg1 completion:(/*^block*/id)arg2 ;
-(void)_handleText:(id)arg1 completion:(/*^block*/id)arg2 ;
-(id)_filterVoices:(id)arg1 gender:(id)arg2 ;
-(long long)_genderForString:(id)arg1 ;
-(void)powerLevelListener:(id)arg1 powerLevelDidUpdateTo:(float)arg2 ;
-(void)isSynthesisQueueEmpty:(/*^block*/id)arg1 ;
-(void)_setSynthesizer:(id)arg1 ;
-(void)_setSiriClientStateManager:(id)arg1 ;
@end

